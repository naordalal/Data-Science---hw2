
# Data Science ex2

## Our best score:

![](/bestRecord.png)

# Try n.1
## naive bayes algorithm
This algorithm try to compute the probability that a person who survived has the records that are given, against the probability that a person who didnt survived as those records, by referring to each record as independent from the others and choosing by the higher probability.

# pre-processing
we read the the train.csv file into df.

we convert the fields Pclass and survived to factor and remove unnecessary fields.

```{r}
df <-read.csv('Titanic/train.csv',na.strings = "")
df_test <-read.csv('Titanic/test.csv',na.strings = "")

df$Pclass<- as.factor(df$Pclass)
df$Survived<- as.factor(df$Survived)
df<- df[,-c(1,4,9)]
```

### split the data to train and test 

```{r}
indices <- sample(1:nrow(df),nrow(df)*0.8)
train<- df[indices,]
test<- df[-indices,]
```
### running the naive bayse alogirthm on Survived field

```{r}
seed=123
set.seed(seed) 
library(e1071)
nb_model <- naiveBayes(Survived~.,data = train)
```

### read the text.csv file int df_test and convert the fields Pclass and survived to factor and remove unnecessary fields and union cabin fields and gets the PassengersId

```{r}
df_test <-read.csv('Titanic/test.csv',na.strings = "")
ids<- df_test$PassengerId
df_test$Pclass<- as.factor(df_test$Pclass)
df_test<- df_test[,-c(1,3,8)]
nb_model$xlevels[["Cabin"]] <- union(nb_model$xlevels[["Cabin"]], levels(df_test$Cabin))

```

### predict the test

```{r}
new_pred<- predict(nb_model,df_test)
```

[link to the file](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction1/prediction1.R)

[link to the output](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction1/try1.csv)

# Try n.2
## C50 algorithm
Decision trees and rule-based models for pattern recognition.

# pre-processing
we read the the train.csv and test.csv files into df and df_test respectively.

we convert the fields Pclass and survived to factor and remove unnecessary fields.

```{r}
df <-read.csv('Titanic/train.csv',na.strings = "")
df_test <-read.csv('Titanic/test.csv',na.strings = "")

df$Pclass<- as.factor(df$Pclass)
df$Survived<- as.factor(df$Survived)
df<- df[,-c(1,4,9)]
```

## plot
![](/Prediction2/C50Plot.png)

[link to the file](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction2/prediction2.R)

[link to the output](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction2/try2.csv)

# Try n.3
## our score in this try:
![](/Prediction3/try3.png)

## Our algorithm
We took 4 algorithms: RPART, C50, XGB, GBM.
We run the algorithms on the data, and decide that people survived only if 2 of the algorithm return 1.

# pre-processing
we read the the train.csv and test.csv files into df and df_test respectively.

we convert the fields Pclass and survived to factor and remove unnecessary fields.

we create grids foreach algorithm.

```{r}
df <-read.csv('Titanic/train.csv',na.strings = "")
df_test <-read.csv('Titanic/test.csv',na.strings = "")

df$Pclass<- as.factor(df$Pclass)
df$Survived<- as.factor(df$Survived)
df<- df[,-c(1,4,9)]

gbmGrid <- expand.grid(.n.trees=c(5),.interaction.depth=6,.shrinkage=c(0.1,0.3,0.5),.n.minobsinnode=5)
xgbGrid <- expand.grid(.nrounds=20,.max_depth=6,.eta=c(0.1,0.3,0.5),.gamma=0.1,.colsample_bytree=0.5,.min_child_weight=0.01,.subsample=0.7)
rpartGrid <- expand.grid(.cp = 0.001)
c50Grid <- expand.grid(.winnow = c(TRUE,FALSE) , .trials = 5 , .model = 'tree')
```


## C50 plot
![](/Prediction3/C50Plot.png)

## JBM plot
![](/Prediction3/gbmPlot.png)

## XJB plot
![](/Prediction3/xgbPlot.png)

[link to the file](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction3/prediction3.R)

[link to the output](https://github.com/naordalal/DataScience-hw2/blob/master/Prediction3/try3.csv)
